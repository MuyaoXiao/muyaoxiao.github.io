<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>概率论 on New River, New Water</title>
    <link>https://muyaoxiao.github.io/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/</link>
    <description>Recent content in 概率论 on New River, New Water</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 Jan 2020 19:15:01 +0000</lastBuildDate><atom:link href="https://muyaoxiao.github.io/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>从马尔可夫不等式到弱大数定律</title>
      <link>https://muyaoxiao.github.io/2020/01/18/%E4%BB%8E%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F%E5%88%B0%E5%BC%B1%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B/</link>
      <pubDate>Sat, 18 Jan 2020 19:15:01 +0000</pubDate>
      
      <guid>https://muyaoxiao.github.io/2020/01/18/%E4%BB%8E%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F%E5%88%B0%E5%BC%B1%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B/</guid>
      <description>回过头来看，从马尔可夫不等式到大数定律的推导，乃是概率论到统计学的桥梁。过去一直对这里感到迷茫，但其实稍微整理一下就会很清楚：
首先是Markov不等式。 它是以俄国数学家Andrey Andreyevich Markov的名字命名，同时也有Markov Chain这个在信息论上著名的东西。这个不等式，简单而言，就是我们可以一个随机变量的期望值判断这个随机变量取值的概率：
$$P(X \geq a) \leq \dfrac{E[X]}{a} (given \ X \geq 0)$$
显而易见，随机变量大于更大的(a)的概率会越低。比方说，当​ ( a = E[X] )的时候，我们有​( P(X \geq E[x]) \leq 1 ) , 这句话没有带来任何信息，因为概率必定小于等于1。 但如果( a = 2E[X] )​, 我们可以得到( P(X \geq 2E[X]) \leq 0.5 )​, 也就是说随机变量取值大于等于两倍期望值的概率必然不大于50%. 马尔可夫不等式维基百科上举例也清晰易懂:
「概率导论」 一书构造了一个随机变量​ (Y_a)来证明这个不等式:
$$
\begin{equation}
Y_a=
\begin{cases}
0, (X &amp;lt; a) \
a, (X \geq a)
\end{cases}
\end{equation}
$$
那么:
$$E[Y_a] = P(X &amp;lt; a) * 0 + P(X \geq a) * a = a*P(X \geq a)$$</description>
    </item>
    
  </channel>
</rss>
